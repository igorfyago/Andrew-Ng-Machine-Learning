{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 23,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark, master=local[*]) created by __init__ at <ipython-input-11-8535d7b3c43c>:3 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8535d7b3c43c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pyspark'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    306\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 308\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    309\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark, master=local[*]) created by __init__ at <ipython-input-11-8535d7b3c43c>:3 "
     ]
    }
   ],
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName('pyspark')\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
=======
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Path does not exist: file:/home/cloudera/Downloads/big-data-4/daily_weather.csv;'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o64.load.\n: org.apache.spark.sql.AnalysisException: Path does not exist: file:/home/cloudera/Downloads/big-data-4/daily_weather.csv;\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:715)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:389)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$15.apply(DataSource.scala:389)\r\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\r\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\r\n\tat scala.collection.immutable.List.foreach(List.scala:381)\r\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\r\n\tat scala.collection.immutable.List.flatMap(List.scala:344)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:388)\r\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:239)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:227)\r\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d5173d252087>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                           \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'com.databricks.spark.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                           \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'true'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                           inferSchema = 'true')\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: 'Path does not exist: file:/home/cloudera/Downloads/big-data-4/daily_weather.csv;'"
     ]
    }
   ],
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "source": [
    "df = sqlContext.read.load('file:///home/cloudera/Downloads/big-data-4/daily_weather.csv',\n",
    "                          format = 'com.databricks.spark.csv',\n",
    "                          header = 'true',\n",
    "                          inferSchema = 'true')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.load('C:/Users/igory/Documents/GitHub/machine_learning_shared/Coursera-lectures/BD_UCSD/big-data-4/daily_weather.csv',\n",
    "                          format = 'com.databricks.spark.csv',\n",
    "                          header = 'true',\n",
    "                          inferSchema = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number',\n",
       " 'air_pressure_9am',\n",
       " 'air_temp_9am',\n",
       " 'avg_wind_direction_9am',\n",
       " 'avg_wind_speed_9am',\n",
       " 'max_wind_direction_9am',\n",
       " 'max_wind_speed_9am',\n",
       " 'rain_accumulation_9am',\n",
       " 'rain_duration_9am',\n",
       " 'relative_humidity_9am',\n",
       " 'relative_humidity_3pm']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 4,
=======
     "execution_count": 30,
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 31,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|avg_wind_speed_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1092|\n",
      "|   mean|  5.50828424225493|\n",
      "| stddev|4.5528134655317185|\n",
      "|    min|  0.69345139999974|\n",
      "|    max|23.554978199999763|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('avg_wind_speed_9am').show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 32,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|summary|rain_accumulation_9am|\n",
      "+-------+---------------------+\n",
      "|  count|                 1089|\n",
      "|   mean|  0.20307895225211126|\n",
      "| stddev|   1.5939521253574893|\n",
      "|    min|                  0.0|\n",
      "|    max|    24.01999999999907|\n",
      "+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('rain_accumulation_9am').show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 33,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095"
      ]
     },
<<<<<<< HEAD
     "execution_count": 7,
=======
     "execution_count": 33,
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 34,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8830741909793918"
      ]
     },
<<<<<<< HEAD
     "execution_count": 8,
=======
     "execution_count": 34,
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stat.corr('relative_humidity_9am','relative_humidity_3pm')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 35,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|max_wind_speed_9am|\n",
      "+-------+------------------+\n",
      "|  count|              1091|\n",
      "|   mean| 7.019513529175272|\n",
      "| stddev| 5.598209170780958|\n",
      "|    min|1.1855782000000479|\n",
      "|    max| 29.84077959999996|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe('max_wind_speed_9am').show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 36,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------+\n",
      "|max_wind_direction_9am|max_wind_speed_9am|\n",
      "+----------------------+------------------+\n",
      "|      67.9999999999999| 29.84077959999996|\n",
      "+----------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('max_wind_direction_9am', 'max_wind_speed_9am').filter(\"max_wind_speed_9am > 29\").show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 37,
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  3.,  7.,  7., 11.,  7., 14., 18., 24., 23., 31., 20., 15.,\n",
       "        28., 18., 24., 33., 34., 38., 43., 43., 40., 48., 43., 34., 61.,\n",
       "        49., 32., 37., 50., 55., 34., 34., 22., 29., 13., 22.,  9., 10.,\n",
       "         9.,  8.,  1.,  3.,  2.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       " array([36.752  , 37.99508, 39.23816, 40.48124, 41.72432, 42.9674 ,\n",
       "        44.21048, 45.45356, 46.69664, 47.93972, 49.1828 , 50.42588,\n",
       "        51.66896, 52.91204, 54.15512, 55.3982 , 56.64128, 57.88436,\n",
       "        59.12744, 60.37052, 61.6136 , 62.85668, 64.09976, 65.34284,\n",
       "        66.58592, 67.829  , 69.07208, 70.31516, 71.55824, 72.80132,\n",
       "        74.0444 , 75.28748, 76.53056, 77.77364, 79.01672, 80.2598 ,\n",
       "        81.50288, 82.74596, 83.98904, 85.23212, 86.4752 , 87.71828,\n",
       "        88.96136, 90.20444, 91.44752, 92.6906 , 93.93368, 95.17676,\n",
       "        96.41984, 97.66292, 98.906  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 11,
=======
     "execution_count": 37,
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Show histogram of the 'C1' column\n",
    "bins, counts = df.select('air_temp_9am').rdd.flatMap(lambda x: x).histogram(50)\n",
    "\n",
    "# This is a bit awkward but I believe this is the correct way to do it \n",
    "plt.hist(bins[:-1], bins=bins, weights=counts)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
=======
   "execution_count": 42,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
=======
   "execution_count": 40,
   "metadata": {},
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
<<<<<<< HEAD
   "source": [
    "print('57')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>1095</td>\n",
       "      <td>547.0</td>\n",
       "      <td>316.24357700987383</td>\n",
       "      <td>0</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_pressure_9am</th>\n",
       "      <td>1092</td>\n",
       "      <td>918.8825513138097</td>\n",
       "      <td>3.1841611803868353</td>\n",
       "      <td>907.9900000000024</td>\n",
       "      <td>929.3200000000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_temp_9am</th>\n",
       "      <td>1090</td>\n",
       "      <td>64.93300141287075</td>\n",
       "      <td>11.175514003175877</td>\n",
       "      <td>36.752000000000685</td>\n",
       "      <td>98.90599999999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_wind_direction_9am</th>\n",
       "      <td>1091</td>\n",
       "      <td>142.23551070057584</td>\n",
       "      <td>69.13785928889183</td>\n",
       "      <td>15.500000000000046</td>\n",
       "      <td>343.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_wind_speed_9am</th>\n",
       "      <td>1092</td>\n",
       "      <td>5.50828424225493</td>\n",
       "      <td>4.552813465531715</td>\n",
       "      <td>0.69345139999974</td>\n",
       "      <td>23.554978199999763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_wind_direction_9am</th>\n",
       "      <td>1092</td>\n",
       "      <td>148.9535179651692</td>\n",
       "      <td>67.23801294602951</td>\n",
       "      <td>28.89999999999991</td>\n",
       "      <td>312.19999999999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_wind_speed_9am</th>\n",
       "      <td>1091</td>\n",
       "      <td>7.019513529175272</td>\n",
       "      <td>5.59820917078096</td>\n",
       "      <td>1.1855782000000479</td>\n",
       "      <td>29.84077959999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_accumulation_9am</th>\n",
       "      <td>1089</td>\n",
       "      <td>0.20307895225211126</td>\n",
       "      <td>1.5939521253574904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.01999999999907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain_duration_9am</th>\n",
       "      <td>1092</td>\n",
       "      <td>294.1080522756142</td>\n",
       "      <td>1598.078778660148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_humidity_9am</th>\n",
       "      <td>1095</td>\n",
       "      <td>34.24140205923539</td>\n",
       "      <td>25.472066802250044</td>\n",
       "      <td>6.090000000001012</td>\n",
       "      <td>92.6200000000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_humidity_3pm</th>\n",
       "      <td>1095</td>\n",
       "      <td>35.34472714825902</td>\n",
       "      <td>22.52407945358728</td>\n",
       "      <td>5.3000000000006855</td>\n",
       "      <td>92.2500000000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0         ...                           4\n",
       "summary                 count         ...                         max\n",
       "number                   1095         ...                        1094\n",
       "air_pressure_9am         1092         ...           929.3200000000012\n",
       "air_temp_9am             1090         ...           98.90599999999992\n",
       "avg_wind_direction_9am   1091         ...                       343.4\n",
       "avg_wind_speed_9am       1092         ...          23.554978199999763\n",
       "max_wind_direction_9am   1092         ...          312.19999999999993\n",
       "max_wind_speed_9am       1091         ...           29.84077959999996\n",
       "rain_accumulation_9am    1089         ...           24.01999999999907\n",
       "rain_duration_9am        1092         ...                     17704.0\n",
       "relative_humidity_9am    1095         ...            92.6200000000002\n",
       "relative_humidity_3pm    1095         ...            92.2500000000003\n",
       "\n",
       "[12 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputeDF=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i removed 31 rows\n"
     ]
    }
   ],
   "source": [
    "removeAllDF=df.na.drop()\n",
    "diff=df.count()-removeAllDF.count()\n",
    "print(\"i removed {} rows\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 545.0018796992481\n",
      "air_pressure_9am 918.9031798641055\n",
      "air_temp_9am 65.02260949558739\n",
      "avg_wind_direction_9am 142.30675564934032\n",
      "avg_wind_speed_9am 5.485793050713691\n",
      "max_wind_direction_9am 148.48042413321312\n",
      "max_wind_speed_9am 6.9997136588756925\n",
      "rain_accumulation_9am 0.18202347650615522\n",
      "rain_duration_9am 266.3936973996038\n",
      "relative_humidity_9am 34.07743985327712\n",
      "relative_humidity_3pm 35.14838093290537\n"
     ]
    }
   ],
   "source": [
    "for x in inputeDF.columns:\n",
    "    meanValue = removeAllDF.agg(avg(x)).first()[0]\n",
    "    print(x, meanValue)\n",
    "    inputeDF = inputeDF.na.fill(meanValue, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(air_pressure_9am)|\n",
      "+-----------------------+\n",
      "|                     77|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Quiz1: If we remove all missing values from the data, \n",
    "#how many air pressure at 9am measurements have values between 911.736 and 914.67?\n",
    "\n",
    "removeAllDF \\\n",
    ".filter(removeAllDF.air_pressure_9am>=911.736) \\\n",
    ".filter(removeAllDF.air_pressure_9am<=914.67) \\\n",
    ".agg(count(removeAllDF.air_pressure_9am)) \\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_temp_9am 36.752000000000685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we impute the missing values with the minimum value, \n",
    "#how many air temperature at 9am measurements are less than 42.292?\n",
    "\n",
    "inputeDF2=df.select('air_temp_9am')\n",
    "\n",
    "for x in inputeDF2.columns:\n",
    "    meanValue = removeAllDF.agg(min(x)).first()[0]\n",
    "    print(x, meanValue)\n",
    "    inputeDF2 = inputeDF2.na.fill(meanValue, [x])\n",
    "    \n",
    "inputeDF2.filter(inputeDF2.air_temp_9am<42.292).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------------+----+\n",
      "|summary|air_pressure_9am|air_pressure_9am|diff|\n",
      "+-------+----------------+----------------+----+\n",
      "|  count|            1092|            1095| 3.0|\n",
      "+-------+----------------+----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Quiz3: How many samples have missing values for air_pressure_9am?\n",
    "\n",
    "df1=df.describe('air_pressure_9am')\n",
    "df2=inputeDF.describe('air_pressure_9am')\n",
    "\n",
    "df3=df1.join(df2,df1.summary==df2.summary)\n",
    "\n",
    "df3.select(\n",
    "    df1.summary,\n",
    "    df1.air_pressure_9am,\n",
    "    df2.air_pressure_9am,(df2.air_pressure_9am-df1.air_pressure_9am).alias('diff')\n",
    ").filter(\n",
    "    df1.summary=='count'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rain_accumulation_9am</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "rain_accumulation_9am  6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quiz4: Which column in the weather dataset has the most number of missing values?\n",
    "\n",
    "nullsDF=df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "nullsDF.toPandas().transpose().sort_values(by=0, ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exploring dictionary to df\n",
    "\n",
    "d = {}\n",
    "\n",
    "for x in nullsDF.columns:\n",
    "    y = nullsDF.agg(max(x)).first()[0]\n",
    "    d[x] = y\n",
    "    \n",
    "#pd.DataFrame.from_dict(d, orient='index', columns=['Amount']).sort_values(by=['Amount'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
=======
>>>>>>> af48fd5efe70ac5fb7255556a77bc313aa5a16e0
   "source": [
    "# When we remove all the missing values from the dataset, \n",
    "#the number of rows is 1064, yet the variable with most missing values has 1089 rows. \n",
    "#Why did the number of rows decrease so much?\n",
    "\n",
    "print('Because the missing values in each column are not necessarily in the same row')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
